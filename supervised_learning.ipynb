{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADNET_SL-pro-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IcGOJV2N7Ad",
        "outputId": "dd5d52ca-4e48-4d4d-d023-54c26fc62324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# This must be run within a Google Colab environment \n",
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "MROyUjtyEJvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85bb996-d6f3-4771-d15b-7aad079d9451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/gdrive/My Drive/EE6885/')\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/EE6885/\")"
      ],
      "metadata": {
        "id": "14ZvtDf8N84s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls adnet_datasets/OTB"
      ],
      "metadata": {
        "id": "j3nz_yHdOCMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd67235-e9c9-4ed3-b54c-0ac5b296d4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basketball  Bolt  CarDark   Crossing  Dudek\tHuman6\t Man\t       RedTeam\n",
            "Bird2\t    Box   CarScale  Crowds    FaceOcc2\tJumping  Matrix        Skater\n",
            "BlurCar3    Boy   ClifBar   Deer      Fish\tLemming  MotorRolling  Skating1\n",
            "Board\t    Car4  Coupon    Doll      Human2\tLiquor\t Panda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "import scipy.io as sio\n",
        "import random\n",
        "from random import choices\n",
        "\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhokYPlsOD_m",
        "outputId": "0b7b2524-b75c-4f81-c365-ee0d94e8c796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ADNET(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (1,1,110))\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1,1), padding = 'VALID', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID', name = 'fc3',activation=\"softmax\")\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        return action\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))\n",
        "      \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ],
      "metadata": {
        "id": "AUxx16wmOE-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ADNET_v2(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET_v2, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (110))\n",
        "\n",
        "        self.resnet=tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=\"max\")\n",
        "        #self.resnet = tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=None)\n",
        "        #self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), padding = 'VALID', name = 'fc4',activation=\"relu\")\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Dense(256,kernel_initializer='glorot_uniform',activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Dense(128,kernel_initializer='glorot_uniform', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Dense(11,kernel_initializer='glorot_uniform', name = 'fc3',activation=\"softmax\")\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET_v2, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "      self.resnet.trainable = False\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.resnet(input_tensor)\n",
        "        #x = self.conv1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        return action\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))\n",
        "     \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ],
      "metadata": {
        "id": "T8R20QIvnwXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ground_truths(ground_truth_file: str) -> np.array:\n",
        "  '''\n",
        "  Use me to convert a ground_truth_file to a numpy array\n",
        "  '''\n",
        "  with open(ground_truth_file) as f:\n",
        "    ground_truths = f.readlines()\n",
        "    to_nparray = lambda s: np.array(re.findall('\\d+', s), dtype=int)\n",
        "    truths = list(map(to_nparray, ground_truths))\n",
        "    return np.asarray(truths)\n",
        "  return None"
      ],
      "metadata": {
        "id": "T5K0BOqeRwNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MOVEMENT helper functions\n",
        "\n",
        "ALPHA = 0.03 # See p. 4 of the paper\n",
        "STOP_ACTION_INDEX = 8\n",
        "MIN_WINDOW_SIZE = 10\n",
        "\n",
        "def calculate_IOU(bbox1: np.array, bbox2: np.array):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "           \n",
        "    i_x1 = max(x1, x2)\n",
        "    i_y1 = max(y1, y2)\n",
        "    i_x2 = min(x1 + w1, x2 + w2)\n",
        "    i_y2 = min(y1 + h1, y2 + h2)\n",
        "    if i_x1 >= i_x2 or i_y1 >= i_y2:\n",
        "      return 0.0\n",
        "\n",
        "    intersection_area = (i_x2 - i_x1) * (i_y2 - i_y1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    \n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def move(img_shape: tuple, bbox: np.array, action: str, \n",
        "         stride_magnitude: int=1) -> np.array:\n",
        "  '''\n",
        "  Returns the new bounding box after taking an action: \n",
        "  {\"left\", \"right\", \"up\", \"down\"}. Use stride to indicate the step size.\n",
        "  '''\n",
        "  if action not in set([\"left\", \"right\", \"up\", \"down\"]):\n",
        "    raise RuntimeError(\"Invalid action taken :(\") \n",
        "  \n",
        "  x, y, w, h = bbox\n",
        "  if action in set([\"left\", \"right\"]):\n",
        "    step = max(1, int(ALPHA * w)) * stride_magnitude * (-1 if action==\"left\" else 1)\n",
        "    x = min(max(0, int(x + step)), int(img_shape[1] - w - 1)) \n",
        "  else:\n",
        "    step = max(1, int(ALPHA * h)) * stride_magnitude * (-1 if action==\"up\" else 1)\n",
        "    y = min(max(0, int(y + step)), int(img_shape[0] - h - 1)) \n",
        "\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "def scale(img_shape: tuple, bbox: np.array, scaleUp: bool):\n",
        "  x, y, w, h = bbox\n",
        "  deltaW, deltaH = max(2, ALPHA * w), max(2, ALPHA * h)\n",
        "  if not scaleUp: \n",
        "    deltaW *= -1\n",
        "    deltaH *= -1\n",
        "  w = min(img_shape[1], max(MIN_WINDOW_SIZE, int(w + deltaW))) \n",
        "  h = min(img_shape[0], max(MIN_WINDOW_SIZE, int(h + deltaH)))\n",
        "  x = max(0, min(int(x + -1 * deltaW / 2), int(img_shape[1] - w - 1)))\n",
        "  y = max(0, min(int(y + -1 * deltaH / 2), int(img_shape[0] - h - 1)))\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def selectAction(img_shape: tuple, bbox: np.array, index: int): \n",
        "  if index == 0 :\n",
        "    bbox = move(img_shape, bbox, \"left\")\n",
        "  elif index == 1 :\n",
        "    bbox = move(img_shape, bbox, \"left\", stride_magnitude=2)\n",
        "  elif index == 2 :\n",
        "    bbox = move(img_shape, bbox, \"right\")\n",
        "  elif index == 3 :\n",
        "    bbox = move(img_shape, bbox, \"right\", stride_magnitude=2)  \n",
        "  elif index == 4 :\n",
        "    bbox = move(img_shape, bbox, \"up\")  \n",
        "  elif index == 5 :\n",
        "    bbox = move(img_shape, bbox, \"up\", stride_magnitude=2)\n",
        "  elif index == 6 :\n",
        "    bbox = move(img_shape, bbox, \"down\")\n",
        "  elif index == 7 :\n",
        "    bbox = move(img_shape, bbox, \"down\", stride_magnitude=2)\n",
        "  elif index == 8:\n",
        "    bbox = bbox\n",
        "  elif index == 9 :\n",
        "    # Scale Down\n",
        "    bbox = scale(img_shape, bbox, False)\n",
        "  elif index == 10 :\n",
        "    # Scale Up\n",
        "    bbox = scale(img_shape, bbox, True)  \n",
        "  return bbox\n",
        "def isStop(action: int):\n",
        "  return action == STOP_ACTION_INDEX"
      ],
      "metadata": {
        "id": "VHB2dNPma_qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPatch(img: np.array, bbox: np.array) -> tf.Tensor:\n",
        "  def _getImagefromBbox(img: np.array, bbox: np.array) -> np.array:\n",
        "    x, y, w, h, = bbox\n",
        "    return img[y : (y + h), x : (x + w)]\n",
        "\n",
        "  patch = tf.image.resize(_getImagefromBbox(img, bbox),[112, 112])\n",
        "  #patch = tf.cast(patch, dtype=tf.uint8)\n",
        "  return tf.reshape(patch, (112, 112, 3))"
      ],
      "metadata": {
        "id": "GDgQ8NNyp3uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFrame(f_path: str) -> np.array:\n",
        "  img = cv2.imread(f_path)\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "AK_6LhQ2lvsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateBBox(original_bbox: np.array,number_of_sample: int ,img_shape: tuple) -> np.array:\n",
        "  counter = 0\n",
        "  x, y, w, h = original_bbox\n",
        "  cov_matrix = np.diag([pow((0.05 * w), 2), pow((0.05 * h), 2), pow((0.1 * w), 2), pow((0.1 * h), 2)])\n",
        "  #random_noises = np.random.multivariate_normal([0, 0, 0, 0], cov_matrix,number_of_sample).astype(np.int64)\n",
        "  #generated_bboxes = [original_bbox + noise for noise in random_noises]\n",
        "  generated_bboxes = []\n",
        "  #for noise in random_noises:\n",
        "  while (counter != number_of_sample):\n",
        "    noise = np.random.multivariate_normal([0, 0, 0, 0], cov_matrix,1).astype(np.int64)[0]\n",
        "    x, y, w, h = original_bbox + noise\n",
        "    if not (x + w > img_shape[1] or x + w < 0 or y + h > img_shape[0] or y + h < 0 or w <= 0 or h <= 0 or x < 0 or y < 0):\n",
        "      generated_bboxes.append([x, y, w, h])\n",
        "      counter += 1\n",
        "  generated_bboxes.append(original_bbox)\n",
        "  return generated_bboxes"
      ],
      "metadata": {
        "id": "sDJ6sHOVU8Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateActionLabels(original_bbox: np.array, generated_bboxes: np.array, img_shape: tuple) -> list:\n",
        "  action_labels = []\n",
        "  for generated_bbox in generated_bboxes:\n",
        "    iou_scores = []\n",
        "    for i in range(11):\n",
        "      new_bbox = selectAction(img_shape, generated_bbox, i)\n",
        "      #print(new_bbox,generated_bbox,np.sum(new_bbox == generated_bbox) == 4)\n",
        "      if np.sum(new_bbox == generated_bbox) == 4 and i != 8:\n",
        "        iou_scores.append(0)\n",
        "      else:\n",
        "        #print(\"Before Action : {}, After Action : {}\".format(bbox,new_bbox))\n",
        "        iou_scores.append(calculate_IOU(new_bbox,original_bbox))\n",
        "    #print(iou_scores)\n",
        "    action_labels.append(np.argmax(iou_scores))\n",
        "  #print(original_bbox)\n",
        "  #print(generated_bboxes)\n",
        "  #print(action_labels)\n",
        "  return action_labels"
      ],
      "metadata": {
        "id": "H2bdKsrIZsnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_generator(ALL_DATASETS_LIST: list, number_of_frames: int, K: int):\n",
        "  #dataset_list = [*range(0,len(ALL_DATASETS_LIST))]\n",
        "  dataset_list = [*range(0,1)]\n",
        "  while (True):\n",
        "    #random_idxs = np.random.choice(dataset_list,len(ALL_DATASETS_LIST),replace=False)\n",
        "    random_idxs = np.random.choice(dataset_list,1,replace=False)\n",
        "    for rand_idx in random_idxs:\n",
        "      ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "      d = ALL_DATASETS_LIST[rand_idx] \n",
        "      gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "      frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "      if len(frames)!= 0:\n",
        "        folder_name = os.path.join('%s/img' % d)\n",
        "        img_shape = cv2.imread(frames[0]).shape[:2]\n",
        "        #print(\"Selected Dataset : {}, # of Frames {}\".format(folder_name,len(frames)))\n",
        "        selected_frames= []\n",
        "        original_bboxs = []\n",
        "        for i in range(number_of_frames):\n",
        "          idx = random.randint(0, len(frames)- 1)\n",
        "          selected_frames.append(frames[idx])\n",
        "          original_bboxs.append(gt[idx])\n",
        "        images = [] \n",
        "        labels = []\n",
        "        for original_bbox in original_bboxs:\n",
        "          index = 0\n",
        "          generated_bboxes = generateBBox(original_bbox, K, img_shape)\n",
        "          selected_actions = generateActionLabels(original_bbox, generated_bboxes, img_shape)\n",
        "          for generated_bbox in generated_bboxes:\n",
        "            images.append(getPatch(getFrame(selected_frames[index]),generated_bbox))\n",
        "            labels.append(selected_actions[index])\n",
        "            index += 1\n",
        "        dataset = list(zip(images, labels))\n",
        "        random.shuffle(dataset)\n",
        "        images, labels = zip(*dataset)\n",
        "        images = tf.reshape(images, (-1,112,112,3))\n",
        "        labels = tf.reshape(labels, (-1,1))\n",
        "        #print(labels)\n",
        "        #print(images[:128].shape)\n",
        "        yield images[:128], labels[:128]"
      ],
      "metadata": {
        "id": "yoTlmCuXgHB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "images = []\n",
        "labels = []\n",
        "#random_idxs = np.random.choice(len(ALL_DATASETS_LIST),20,replace=False)\n",
        "for random_idx in range(14,15):\n",
        "  d = ALL_DATASETS_LIST[random_idx]\n",
        "  print(\"Generated Dataset {}\".format(d))\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "  img_shape = cv2.imread(frames[0]).shape[:2]\n",
        "  for i in range(len(frames)):\n",
        "    generated_bboxes = generateBBox(gt[i],10,img_shape)\n",
        "    selected_actions = generateActionLabels(gt[i], generated_bboxes, img_shape)\n",
        "    for j in range(len(generated_bboxes)):\n",
        "      images.append(getPatch(getFrame(frames[i]),generated_bboxes[j]))\n",
        "      labels.append(selected_actions[j])\n",
        "temp = list(zip(images, labels))\n",
        "random.shuffle(temp)\n",
        "images, labels = zip(*temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "fQEQ4bhzLGvS",
        "outputId": "ce220a72-7fbd-450e-b316-995a0b4e27d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Dataset adnet_datasets/OTB/Deer\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3ec073253eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mselected_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateActionLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_bboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetPatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerated_bboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e6f6433af6a4>\u001b[0m in \u001b[0;36mgetPatch\u001b[0;34m(img, bbox)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getImagefromBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;31m#patch = tf.cast(patch, dtype=tf.uint8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1721\u001b[0m       \u001b[0mpreserve_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreserve_aspect_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m       skip_resize_if_same=False)\n\u001b[0m\u001b[1;32m   1724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1385\u001b[0m   \u001b[0;34m\"\"\"Core functionality for v1 and v2 resize functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\'images\\' contains no shape.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i saved one by one, collab crashes if not.\n",
        "np.save(\"/content/gdrive/MyDrive/sl-training/Deer\",images)\n",
        "np.save(\"/content/gdrive/MyDrive/sl-training/Deer-labels\",labels)"
      ],
      "metadata": {
        "id": "h6lemyI0XU2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load np arrays and create a dataset\n",
        "dsets = sorted(glob.glob(os.path.join('/content/gdrive/MyDrive/sl-training/*')))\n",
        "j = 1\n",
        "images = []\n",
        "labels = []\n",
        "index = 0\n",
        "for i in range(0,len(dsets),2):\n",
        "  print(dsets[j])\n",
        "  print(dsets[i])\n",
        "  images.append(np.load(dsets[j]))\n",
        "  labels.append(np.load(dsets[i]))\n",
        "  j += 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDCYcf28dFZQ",
        "outputId": "486f6fb6-84c5-4137-b86d-6efd8d84ad61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/sl-training/Basketball.npy\n",
            "/content/gdrive/MyDrive/sl-training/Basketball-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/Bird2.npy\n",
            "/content/gdrive/MyDrive/sl-training/Bird2-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/BlurCar3.npy\n",
            "/content/gdrive/MyDrive/sl-training/BlurCar3-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/Boy.npy\n",
            "/content/gdrive/MyDrive/sl-training/Boy-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/CarDark.npy\n",
            "/content/gdrive/MyDrive/sl-training/CarDark-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/CarScale.npy\n",
            "/content/gdrive/MyDrive/sl-training/CarScale-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/ClifBar.npy\n",
            "/content/gdrive/MyDrive/sl-training/ClifBar-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/Coupon.npy\n",
            "/content/gdrive/MyDrive/sl-training/Coupon-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/Crowds.npy\n",
            "/content/gdrive/MyDrive/sl-training/Crowds-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/Deer.npy\n",
            "/content/gdrive/MyDrive/sl-training/Deer-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/FaceOcc2.npy\n",
            "/content/gdrive/MyDrive/sl-training/FaceOcc2-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/Fish.npy\n",
            "/content/gdrive/MyDrive/sl-training/Fish-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/Human6.npy\n",
            "/content/gdrive/MyDrive/sl-training/Human6-labels.npy\n",
            "/content/gdrive/MyDrive/sl-training/MotorRolling.npy\n",
            "/content/gdrive/MyDrive/sl-training/MotorRolling-labels.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_np = np.concatenate([np.array(i) for i in images])\n",
        "labels_np = np.concatenate([np.array(i) for i in labels])\n",
        "images_np = images_np[:int(images_np.shape[0]/128)*128]\n",
        "labels_np = labels_np[:int(images_np.shape[0]/128)*128]"
      ],
      "metadata": {
        "id": "xClj-WVdjJWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del images\n",
        "del labels"
      ],
      "metadata": {
        "id": "aWNqq4tHkeEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "images_np,labels_np = shuffle(images_np, labels_np, random_state=0)"
      ],
      "metadata": {
        "id": "Vn9XUIEql-ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create tf dataset object from shuffled numpy training dataset. Set batch size for the training,validation and the test dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((images_np, labels_np))\n",
        "BATCH_SIZE = 128\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "vf7bR6pFPK3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "adamOptimizer = Adam(learning_rate=0.001)\n",
        "model = ADNET()\n",
        "action_hist = np.zeros(shape = (128,1,1,110))\n",
        "model.build(action_hist)\n",
        "model.compile(adamOptimizer)\n",
        "model.fit(train_dataset,epochs=100,verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZsL3L79Onj6",
        "outputId": "a41337b8-56ec-408f-ad77-7918d5149066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "506/506 [==============================] - 40s 64ms/step - loss: 2.6782\n",
            "Epoch 2/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 2.0904\n",
            "Epoch 3/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.9376\n",
            "Epoch 4/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.8517\n",
            "Epoch 5/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.7931\n",
            "Epoch 6/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.7425\n",
            "Epoch 7/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.7117\n",
            "Epoch 8/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.6819\n",
            "Epoch 9/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.6400\n",
            "Epoch 10/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.6132\n",
            "Epoch 11/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.5788\n",
            "Epoch 12/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.5549\n",
            "Epoch 13/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.5396\n",
            "Epoch 14/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.5293\n",
            "Epoch 15/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.5093\n",
            "Epoch 16/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.4751\n",
            "Epoch 17/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.4652\n",
            "Epoch 18/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.4503\n",
            "Epoch 19/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.4490\n",
            "Epoch 20/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.4294\n",
            "Epoch 21/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.4127\n",
            "Epoch 22/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.3946\n",
            "Epoch 23/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.4137\n",
            "Epoch 24/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.3952\n",
            "Epoch 25/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.3714\n",
            "Epoch 26/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.3613\n",
            "Epoch 27/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.3472\n",
            "Epoch 28/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.3195\n",
            "Epoch 29/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.3060\n",
            "Epoch 30/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.3108\n",
            "Epoch 31/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.2908\n",
            "Epoch 32/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.2703\n",
            "Epoch 33/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.2547\n",
            "Epoch 34/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.2448\n",
            "Epoch 35/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.2520\n",
            "Epoch 36/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.2529\n",
            "Epoch 37/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.2407\n",
            "Epoch 38/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.2414\n",
            "Epoch 39/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.2287\n",
            "Epoch 40/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.2524\n",
            "Epoch 41/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.2234\n",
            "Epoch 42/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.2063\n",
            "Epoch 43/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.1930\n",
            "Epoch 44/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.1813\n",
            "Epoch 45/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.1948\n",
            "Epoch 46/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.1746\n",
            "Epoch 47/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.1366\n",
            "Epoch 48/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.1042\n",
            "Epoch 49/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.0974\n",
            "Epoch 50/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.1336\n",
            "Epoch 51/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.1282\n",
            "Epoch 52/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 1.1172\n",
            "Epoch 53/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0775\n",
            "Epoch 54/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 1.0564\n",
            "Epoch 55/100\n",
            "506/506 [==============================] - 33s 64ms/step - loss: 1.0582\n",
            "Epoch 56/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0645\n",
            "Epoch 57/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0743\n",
            "Epoch 58/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0545\n",
            "Epoch 59/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0278\n",
            "Epoch 60/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 1.0679\n",
            "Epoch 61/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 1.1167\n",
            "Epoch 62/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.1073\n",
            "Epoch 63/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0818\n",
            "Epoch 64/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.0560\n",
            "Epoch 65/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0493\n",
            "Epoch 66/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0611\n",
            "Epoch 67/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0438\n",
            "Epoch 68/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0571\n",
            "Epoch 69/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0242\n",
            "Epoch 70/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 1.0095\n",
            "Epoch 71/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 0.9978\n",
            "Epoch 72/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 0.9701\n",
            "Epoch 73/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9569\n",
            "Epoch 74/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9717\n",
            "Epoch 75/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9847\n",
            "Epoch 76/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9977\n",
            "Epoch 77/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.0067\n",
            "Epoch 78/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9774\n",
            "Epoch 79/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.0155\n",
            "Epoch 80/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 1.0736\n",
            "Epoch 81/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9916\n",
            "Epoch 82/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9870\n",
            "Epoch 83/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9617\n",
            "Epoch 84/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9799\n",
            "Epoch 85/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9774\n",
            "Epoch 86/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9661\n",
            "Epoch 87/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9421\n",
            "Epoch 88/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9453\n",
            "Epoch 89/100\n",
            "506/506 [==============================] - 33s 65ms/step - loss: 0.9252\n",
            "Epoch 90/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.8994\n",
            "Epoch 91/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9164\n",
            "Epoch 92/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9056\n",
            "Epoch 93/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9210\n",
            "Epoch 94/100\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 0.8925\n",
            "Epoch 95/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9023\n",
            "Epoch 96/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.8816\n",
            "Epoch 97/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9335\n",
            "Epoch 98/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9486\n",
            "Epoch 99/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9238\n",
            "Epoch 100/100\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3cb003f250>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,epochs=5,verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0j8PGwt1-Ym",
        "outputId": "340c115d-2389-4f48-d947-e09c02667102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.8556\n",
            "Epoch 2/5\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.8841\n",
            "Epoch 3/5\n",
            "506/506 [==============================] - 34s 66ms/step - loss: 0.9008\n",
            "Epoch 4/5\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.9105\n",
            "Epoch 5/5\n",
            "506/506 [==============================] - 33s 66ms/step - loss: 0.8913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c21717190>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/gdrive/My Drive/EE6885/kaan-weights')"
      ],
      "metadata": {
        "id": "Nho4diXP7Aag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[ALL_DATASETS_LIST[11]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FijeBlx6Aidj",
        "outputId": "77746483-d2f8-4467-f8cf-2cc17dfc623c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adnet_datasets/OTB/Coupon']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ALL_DATASETS_LIST[21]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cLcNlhE_L5Q",
        "outputId": "a531efe7-196f-49ef-821f-329df54103c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adnet_datasets/OTB/Jumping']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}
